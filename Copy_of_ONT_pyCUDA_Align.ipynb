{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of ONT_pyCUDA_Align.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TomKellyGenetics/toy_snp_caller/blob/master/Copy_of_ONT_pyCUDA_Align.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3L9iwLrKLPc",
        "colab_type": "text"
      },
      "source": [
        "In this exercise we will be creating a python code to generate some artificial DNA sequences that will be our set of reference genes. We will then create a new sequence that is similar to one of the references and create a function that finds the best match. We will measure the performance of this code and then consider how we might create a GPU-accelerated version.\n",
        "\n",
        "First of all let's import a few libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfvOf5fgFnQ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_H6SycDpG4KV",
        "colab_type": "text"
      },
      "source": [
        "Next, set up some constants to define the size of the problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFc8YEaWHFv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "REFERENCE_LENGTH = 500  # The length of the reference sequences\n",
        "SEQUENCE_LENGTH = 100    # The length of the sequence to be generated (before noise is added)\n",
        "NUMBER_REFERENCES = 100  # The number of references in which to find a match\n",
        "\n",
        "# Dictionary that converts the base letters to an integer\n",
        "ascii_to_index = {\"C\": 0, \"G\": 1, \"A\": 2, \"T\": 3}\n",
        "# Array that can be used to get the base letter from the integer value\n",
        "index_to_ascii = [\"C\", \"G\", \"A\", \"T\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKpqNPN6IqSq",
        "colab_type": "text"
      },
      "source": [
        "Create a function to create a populate some artificial reference sequences, which we will be searching for the best alignment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ok8LeC2cJwtG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Randomly assign CAGTs to the reference sequences\n",
        "def initialise_references():\n",
        "    refs = []\n",
        "\n",
        "    for i in range(NUMBER_REFERENCES):\n",
        "        ref = \"\"\n",
        "        for j in range(REFERENCE_LENGTH):\n",
        "            irand = random.randint(0, 3)\n",
        "            ref += index_to_ascii[irand]\n",
        "\n",
        "        refs.append(ref)\n",
        "\n",
        "    return refs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtbeHdTFLDM0",
        "colab_type": "text"
      },
      "source": [
        "Now we are going to generate the sequence to match by randomly selecting one of the reference sequences and then adding some noise to it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G81L_ch6LfOz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Randomly pick one of the references, pick an offset and\n",
        "# add noise - this will be the sequence we'll seek\n",
        "def initialise_sequence(references):\n",
        "\n",
        "    seq = \"\"\n",
        "    # randomly select the reference string to match\n",
        "    iref = random.randint(0, NUMBER_REFERENCES-1)\n",
        "    ref_offset = random.randint(0,REFERENCE_LENGTH - SEQUENCE_LENGTH)\n",
        "    print(\"Actual offset = \" + str(ref_offset) + \" on sequence #\" + str(iref))\n",
        "    ref = references[iref]\n",
        "    dels = 0\n",
        "    subs = 0\n",
        "    ins = 0\n",
        "\n",
        "    for i in range(ref_offset, ref_offset+SEQUENCE_LENGTH):\n",
        "        base = ref[i]\n",
        "        i_rand = random.randint(0, 1000)\n",
        "\n",
        "        if (i_rand < 22):\n",
        "            # Insertion of up to 4 characters\n",
        "            i_len = random.randint(0, 3)\n",
        "            ins += i_len\n",
        "            cnew=\"\"\n",
        "            for i in range(i_len):\n",
        "                irand = random.randrange(0, 3)\n",
        "                cnew += index_to_ascii[irand]\n",
        "\n",
        "            seq+=cnew + base\n",
        "        elif (i_rand < 44):\n",
        "            subs += 1\n",
        "            # Substitute the current character\n",
        "            inew = random.randint(0, 2)\n",
        "            if (base == \"A\"):\n",
        "                cnew = index_to_ascii[inew if (inew == 2) else 3]\n",
        "            elif (base == \"T\"):\n",
        "                cnew = index_to_ascii[inew]\n",
        "            elif (base == \"C\"):\n",
        "                cnew = index_to_ascii[inew+1]\n",
        "            else:\n",
        "                cnew = index_to_ascii[inew if (inew == 1) else 0]\n",
        "\n",
        "            seq+=cnew\n",
        "        elif (i_rand < 66):\n",
        "            # Deletion\n",
        "            dels += 1\n",
        "        else:\n",
        "            seq += base\n",
        "\n",
        "    print(str(subs) + \" subs, \" + str(dels) + \" dels,\" + str(ins) + \" ins\")\n",
        "    print(ref)\n",
        "    print(seq)\n",
        "\n",
        "    return seq\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwrAMsg8hGcb",
        "colab_type": "text"
      },
      "source": [
        "Next, create a cost function. In this case it is simple +1 for a match and -1 for anything else (insertion, deletion or substitution)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1Q31u9ZhUEg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cost(char1, char2):\n",
        "  return -1 if char1!=char2 else +1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBeijbzML2ku",
        "colab_type": "text"
      },
      "source": [
        "Next we create the main alignment function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nyk80VYYMPqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute a cost and, optionally, an offset for the semi-global alignment of seq to ref\n",
        "def align(seq, ref, matrix, trace, compute_trace=False):\n",
        "\n",
        "    max_score = -len(seq)\n",
        "    max_idx = 0\n",
        "\n",
        "    # Initialise the scoring matrices\n",
        "    for i in range(len(seq)):\n",
        "        matrix[i] = -(i+1)\n",
        "        if compute_trace:\n",
        "            trace[i, 0] = -i\n",
        "\n",
        "    # Do the NW matrix calculation (column by column - to preserve memory)\n",
        "    for i, base_r in enumerate(ref):\n",
        "        top_left = 0\n",
        "        bottom_left = matrix[0]\n",
        "        top_right = 0\n",
        "        for j, base_s in enumerate(seq):\n",
        "            cost_m = cost(base_s, base_r) + top_left\n",
        "            cost_i = bottom_left - 1\n",
        "            cost_d = top_right - 1\n",
        "            top_left = matrix[j]\n",
        "            matrix[j] = max(cost_m, cost_i, cost_d)\n",
        "            bottom_left = matrix[j+1]\n",
        "            top_right = matrix[j]\n",
        "\n",
        "            if compute_trace:\n",
        "                if cost_m >= cost_i:\n",
        "                    if cost_m >= cost_d:\n",
        "                        trace[i + 1, j + 1] = [i, j]\n",
        "                    else:\n",
        "                        trace[i + 1, j + 1] = [i + 1, j]\n",
        "                else:\n",
        "                    if cost_i >= cost_d:\n",
        "                        trace[i + 1, j + 1] = [i, j + 1]\n",
        "                    else:\n",
        "                        trace[i + 1, j + 1] = [i + 1, j]\n",
        "\n",
        "        if matrix[len(seq)-1] > max_score:\n",
        "            max_score = matrix[len(seq)-1]\n",
        "            max_idx = i\n",
        "\n",
        "    return max_score, trace, max_idx\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kbd3nQAMVKN",
        "colab_type": "text"
      },
      "source": [
        "We also need a function to compute the cost of the aligment using the back-tracking part of the Needleman-Wunsch algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwHS8DvQMjMY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use the traceback to get the offset\n",
        "def compute_offset(traceback, len_seq, ref, max_idx):\n",
        "\n",
        "    match = \"\"\n",
        "    idx = max_idx\n",
        "    ls = len_seq\n",
        "\n",
        "    # Traceback to get the offset\n",
        "    while ls > 0:\n",
        "        match = ref[idx - 1] + match\n",
        "        idx, ls = traceback[idx, ls]\n",
        "        #print(idx, ls)\n",
        "\n",
        "    return idx\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-WQfdKsND_G",
        "colab_type": "text"
      },
      "source": [
        "Right, now we have all the main functions defined we can create the main body of the program that will execute the functions we defined in order to find the best alignment between our references and the noisy sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZYqMZeJNbw2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "0834d18c-3a06-4416-e12c-d885bb956ccc"
      },
      "source": [
        "offset = 0\n",
        "score = 0\n",
        "max_score = 0\n",
        "ref_idx = 0\n",
        "time_span = 0\n",
        "\n",
        "# For degugging, it can be helpful to set the seed so that the same strings are produced each time\n",
        "#random.seed(30)\n",
        "\n",
        "t1 = time.time()\n",
        "\n",
        "refs = initialise_references()\n",
        "seq = initialise_sequence(refs)\n",
        "\n",
        "# Create arrays for the scoring matrix and traceback matrix\n",
        "score_matrix = np.zeros(len(seq) + 1, dtype=np.int32)\n",
        "trace_matrix = np.zeros((REFERENCE_LENGTH+1, len(seq) + 1, 2), dtype=np.int32)\n",
        "max_score = -len(seq)\n",
        "\n",
        "time_span = time.time() - t1\n",
        "print(\"Data initialisation took \" + str(time_span) + \" milliseconds.\")\n",
        "\n",
        "# Run alignment on the host\n",
        "t1 = time.time()\n",
        "\n",
        "scores=[]\n",
        "for i in range(NUMBER_REFERENCES):\n",
        "    score, _, _ = align(seq, refs[i], score_matrix, trace_matrix)\n",
        "    scores.append(score)\n",
        "    if score > max_score:\n",
        "        max_score = score\n",
        "        ref_idx = i\n",
        "\n",
        "# now get offset\n",
        "score, trace_matrix, offset_idx = align(seq, refs[ref_idx], score_matrix, trace_matrix, compute_trace=True)\n",
        "offset = compute_offset(trace_matrix, len(seq), refs[ref_idx], offset_idx)\n",
        "print(\"Optimal cost of \" + str(max_score) + \" found at offset \" + str(offset) + \" in reference \" + str(ref_idx))\n",
        "time_span = time.time() - t1\n",
        "print(\"Serial took \" + str(time_span) + \" seconds\")"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual offset = 59 on sequence #41\n",
            "2 subs, 4 dels,9 ins\n",
            "CAAAGTCGAACCAAATGCACGAGGAGCCTGGTTTTAAAACGCGGCCCCTGTCCGCTGATGAGCACGTCACGGATGATGAAATCCGATAGTTTATCTGTTCAGCTTCTGGATGGGTAAATGAACATTACGAAAGGGATTTGGTCATCTGTCCGCACACAGGTTTCAGTGCAACCCACTACGCGAATGGGTGTAACAGAGCATTACTGACCTCGAACAGCACAGCCTGTTCCTTGAGTCCCCGGAGCGTGGGCCCCTTAAGTTGGCTTCCTTACGAATAGTAACTGTCTCTAGTTCGAGGTTGTGGGCTTGACCAAGCTCGGTATCTCACCTCAGGGGCGTGGTGGACGGCGGCAAGTTGCGTCTCCAGGCTCTACGATCGGTTGAAAGTCAAACTTGTAGGGGCTCTATATAACTCGCCATATTAATAGTTCACGGGGCCATAACACTGCTACAGAGGCTTTTCACTCTTCAACGAGTACGTGCGTTTGTGCACTAAAGAT\n",
            "GAGGAACACGTCACGGATGAGATGAAATCCGATGTTATCTGTTCAGCTTCGGGATGGCGGGTAAATGAACATTATGAAAGGGATTTGGTCATCTGCCGCACACAC\n",
            "Data initialisation took 0.07340264320373535 milliseconds.\n",
            "Optimal cost of 82 found at offset 56 in reference 41\n",
            "Serial took 41.638463735580444 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZvRPVyLK_EG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "49af08f7-774a-485c-bcfb-a3b1f817f0f7"
      },
      "source": [
        "trace_matrix.shape"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(501, 106, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E09u_dqcnpk9",
        "colab_type": "text"
      },
      "source": [
        "Great - now can you create a kernel to do the alignment? Have a think for 10 minutes before you start implementing anything.\n",
        "\n",
        "We also need to install pycuda and to import the libraries (for this, insert a scratch code window and type 'pip install pycuda')\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbzSScL0ErY3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "f4680b3c-ca29-4ead-e258-cd1901b3066b"
      },
      "source": [
        "pip install pycuda"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pycuda in /usr/local/lib/python3.6/dist-packages (2019.1.2)\n",
            "Requirement already satisfied: pytools>=2011.2 in /usr/local/lib/python3.6/dist-packages (from pycuda) (2019.1.1)\n",
            "Requirement already satisfied: decorator>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from pycuda) (4.4.0)\n",
            "Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from pycuda) (1.4.3)\n",
            "Requirement already satisfied: mako in /usr/local/lib/python3.6/dist-packages (from pycuda) (1.1.0)\n",
            "Requirement already satisfied: six>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.16.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from mako->pycuda) (1.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3STI7UPOaooC",
        "colab_type": "text"
      },
      "source": [
        "100 references x 100 sequence length = computing in parallel\n",
        "\n",
        "500 reference length in serial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imRR-O-0n50f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "f1958443-1d26-4038-ff98-d0b6e741fbe2"
      },
      "source": [
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "from pycuda import gpuarray\n",
        "\n",
        "# Create your kernel (or kernels)\n",
        "parallel_index = SourceModule(\"\"\"\n",
        "    __global__ void compute_index(char *seq, char *ref, int *mat, int len_seq, int len_ref, int max_score)\n",
        "    {\n",
        "      int idx = threadIdx.x + threadIdx.y * blockDim.x ;\n",
        "      int gridSize = gridDim.x * blockDim.x ;\n",
        "      //test index is correct for debugging\n",
        "      mat[idx] = idx ;\n",
        "      //if( idx === 0 ){\n",
        "      //    printf(idx);\n",
        "      //}\n",
        "    }\n",
        "    \"\"\")"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR:root:An unexpected error occurred while tokenizing input\n",
            "The following traceback may be corrupted or invalid\n",
            "The error message is: ('EOF in multi-line string', (1, 4))\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "LogicError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLogicError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-2f5182239701>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m       //}\n\u001b[1;32m     17\u001b[0m     }\n\u001b[0;32m---> 18\u001b[0;31m     \"\"\")\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pycuda/compiler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, source, nvcc, options, keep, no_extern_c, arch, code, cache_dir, include_dirs)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdriver\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_from_buffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule_from_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcubin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bind_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLogicError\u001b[0m: cuModuleLoadDataEx failed: an illegal memory access was encountered - "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aBpM5UWeJir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4bqJjDJd86o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create your kernel (or kernels)\n",
        "parallel_align = SourceModule(\"\"\"\n",
        "    __global__ void compute_align(char* seq, char* refs, int* matrix, int num_refs, int len_seq, int len_ref, int *max_score)\n",
        "    {\n",
        "      int idx = threadIdx.x + threadIdx.y * blockDim.x ;\n",
        "      int gridSize = gridDim.x * blockDim.x ;\n",
        "      \n",
        "      for (int g = idx; g < num_refs; g += gridSize)\n",
        "      {\n",
        "          int offset = len_ref * g;\n",
        "          max_score[g] = -len_seq;\n",
        "          \n",
        "          //initialise scoring matrix\n",
        "          for(int j=0; j < len_seq; j++){\n",
        "              matrix[offset + j] = -(j+1);\n",
        "          }\n",
        "          \n",
        "          //Do the NW matrix calculation (column by column - to preserve memory)\n",
        "          for (int i=0; i < len_ref; i++)\n",
        "          {\n",
        "            char base_r = refs[offset + i ];\n",
        "            int top_left = 0;\n",
        "            int bottom_left = matrix[offset];\n",
        "            int top_right = 0;\n",
        "          \n",
        "            for ( int j=0; j < len_seq; j++)\n",
        "            {\n",
        "               char base_s = seq[j];\n",
        "               int cost_m = (base_s == base_r ? 1 : -1) + top_left;\n",
        "               int cost_i = bottom_left -1;\n",
        "               int cost_d = top_right -1;\n",
        "               int top_left = matrix[offset + j];\n",
        "               matrix[offset + j] = cost_m > cost_i ? (cost_m > cost_d ? cost_m : cost_d) : (cost_i > cost_d ? cost_i : cost_d);\n",
        "               int bottom_left = matrix[offset + j + 1];\n",
        "               int top_right = matrix[offset + j];\n",
        "            }\n",
        "          \n",
        "            if (matrix[offset + len_seq -1 ] > max_score[g])\n",
        "            {\n",
        "               max_score[g] = matrix[offset + len_seq -1];\n",
        "            }\n",
        "          }\n",
        "       }\n",
        "    }\n",
        "    \"\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdSnnuM2JoQn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "outputId": "af1b46ab-30f3-4e88-ebd0-84bb4c1f40ca"
      },
      "source": [
        "offset = 0\n",
        "score = 0\n",
        "max_score = 0\n",
        "ref_idx = 0\n",
        "time_span = 0\n",
        "\n",
        "\n",
        "# Now run the same using our kernel\n",
        "t1 = time.time()\n",
        "\n",
        "refs = initialise_references()\n",
        "seq = initialise_sequence(refs)\n",
        "\n",
        "# Create arrays for the scoring matrix and traceback matrix\n",
        "score_matrix = np.zeros(len(seq) * NUMBER_REFERENCES, dtype=np.int32)\n",
        "trace_matrix = np.zeros((REFERENCE_LENGTH+1, len(seq) + 1, 2), dtype=np.int32)\n",
        "max_score_matrix = np.zeros(NUMBER_REFERENCES, dtype=np.int32)\n",
        "max_score = -len(seq)\n",
        "\n",
        "#convert strings to array\n",
        "seq_byte = bytearray(seq, 'utf8')\n",
        "seq_array = np.array(seq_byte)\n",
        "score_array = np.array(score_matrix)\n",
        "max_score_array = np.array(np.int(max_score))\n",
        "len_seq_array = np.array(np.int(SEQUENCE_LENGTH))\n",
        "len_refs_array = np.array(np.int(REFERENCE_LENGTH))\n",
        "num_refs_array = np.array(np.int(NUMBER_REFERENCES))\n",
        "max_idx_array = np.array(np.int(0))\n",
        "\n",
        "refs_array = []\n",
        "for i in range(len(refs)):\n",
        "  refs_array.append(bytearray(refs[i], 'utf8'))\n",
        "\n",
        "refs_array = np.array(refs_array)\n",
        "  \n",
        "#TODO - Insert data preparation code\n",
        "# Allocate GPU memory\n",
        "score_matrix_gpu = cuda.mem_alloc(score_matrix_array.nbytes)\n",
        "trace_matrix_gpu = cuda.mem_alloc(trace_matrix.nbytes)\n",
        "seq_gpu = cuda.mem_alloc(seq_array.nbytes)\n",
        "refs_gpu = cuda.mem_alloc(refs_array.nbytes)\n",
        "max_score_gpu = cuda.mem_alloc(max_score_array.nbytes)\n",
        "\n",
        "num_refs_gpu = cuda.mem_alloc(num_refs_array.nbytes)\n",
        "len_seq_gpu = cuda.mem_alloc(len_seq_array.nbytes)\n",
        "len_refs_gpu = cuda.mem_alloc(len_refs_array.nbytes)\n",
        "num_refs_gpu = cuda.mem_alloc(num_refs_array.nbytes)\n",
        "max_idx_gpu = cuda.mem_alloc(max_idx_array.nbytes)\n",
        "\n",
        "# set the gpu memory\n",
        "cuda.memcpy_htod(score_matrix_gpu, score_matrix_array)\n",
        "cuda.memcpy_htod(trace_matrix_gpu, trace_matrix)\n",
        "cuda.memcpy_htod(seq_gpu, seq_array)\n",
        "cuda.memcpy_htod(refs_gpu, refs_array)\n",
        "cuda.memcpy_htod(max_score_gpu, max_score_array)\n",
        "\n",
        "cuda.memcpy_htod(num_refs_gpu, num_refs_array)\n",
        "cuda.memcpy_htod(len_seq_gpu, len_seq_array)\n",
        "cuda.memcpy_htod(len_refs_gpu, len_refs_array)\n",
        "cuda.memcpy_htod(num_refs_gpu, num_refs_array)\n",
        "cuda.memcpy_htod(max_idx_gpu, max_idx_array)\n",
        "\n",
        "time_span = time.time() - t1\n",
        "print(\"Data initialisation took \" + str(time_span) + \" milliseconds.\")\n",
        "\n",
        "t1 = time.time()\n",
        "\n",
        "# Get the function handle\n",
        "run_align = parallel_align.get_function(\"compute_align\")\n",
        "# Create a lauch configuration with 10,0000 threads and 1 blockrun_align = parallel_align.get_function(\"compute_align\")\n",
        "run_align(seq_gpu, refs_gpu, score_matrix_gpu, num_refs_gpu, len_seq_gpu, len_refs_gpu, max_score_gpu, block = (64, 1, 1), grid = (64, 1, 1))\n",
        "\n",
        "#run_index = parallel_index.get_function(\"compute_index\")\n",
        "#run_index(seq_gpu, refs_gpu, score_matrix_gpu, block = (64, 1, 1), grid = (64, 1, 1))\n",
        "\n",
        "time_span = time.time() - t1"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual offset = 259 on sequence #78\n",
            "6 subs, 3 dels,0 ins\n",
            "GTCTGACCACAAAATATGTGTGTAAGATGTGATCGGCAGCAGGATGTCACATGTATAGATCTTTAACGTGGTGGGCATGCGCCCTGGTCATTTTGTAGCGGGCCGAGTGCCATATAACCGCGATAGGCAATGCTGGGGGAAAGCGTAGCAGACGTTGTGCAGGGATGCGGATGTTGTCACACGCCGATTTCTGGGGTTATAATTGCAGCAACCTTTCAAAATATCTTGCTTATGACGAATGAGAAGAAGTGCTTTGGCCGTAGACCTTGTTCTTGCGCACCCGTTCTTTGAATGAGATTAATCTAGGCATGTGGCGTGTTTAATGTCGGGGTATCCAACAGCAGCGGAGCGTTGCGAGGGAGATGTTACTCAGCATTGACAAGACAATCCTGAAAATCCTTTGGTTCGCCTATCTTATGTCGACAGGGGAGAGGGCTACCTGCCTTTGTTCTACTGTAAACATTTCGAACGGCCCCAATCGAACTGTTCGTGCCCCGTTA\n",
            "GTAGACCTTGTTCTTGCGGTCCCGTTCTTTGAATGTGATTAATCTAGGCATGTGGCGTGTTTAAGGCGGGGTATCACAGCAGCGGAGCGTTGCGAGG\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-78c789e3186a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m#TODO - Insert data preparation code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Allocate GPU memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mscore_matrix_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmem_alloc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_matrix_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0mtrace_matrix_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmem_alloc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mseq_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmem_alloc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'score_matrix_array' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30GXHMP6iHle",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ae61d32a-b96a-4c56-c67d-a37183830540"
      },
      "source": [
        "print(time_span)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0004024505615234375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXqlefFPgm7o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "3312f230-9848-4170-be5b-5787444366ad"
      },
      "source": [
        "run_index = parallel_index.get_function(\"compute_index\")\n",
        "run_index(seq_gpu, refs_gpu, score_matrix_gpu, block = (64, 1, 1), grid = (64, 1, 1))\n",
        "score_out = np.empty_like(score_matrix)\n",
        "cuda.memcpy_dtoh(score_out, score_matrix_gpu)\n",
        "print(score_out.shape)\n",
        "print(score_out.reshape(10, 10))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100,)\n",
            "[[ 0  1  2  3  4  5  6  7  8  9]\n",
            " [10 11 12 13 14 15 16 17 18 19]\n",
            " [20 21 22 23 24 25 26 27 28 29]\n",
            " [30 31 32 33 34 35 36 37 38 39]\n",
            " [40 41 42 43 44 45 46 47 48 49]\n",
            " [50 51 52 53 54 55 56 57 58 59]\n",
            " [60 61 62 63 64 65 66 67 68 69]\n",
            " [70 71 72 73 74 75 76 77 78 79]\n",
            " [80 81 82 83 84 85 86 87 88 89]\n",
            " [90 91 92 93 94 95 96 97 98 99]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UqsAR86wsyF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2ec59b7f-df19-46c9-aacf-71d5ce3da5c3"
      },
      "source": [
        "score_matrix_gpu"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pycuda._driver.DeviceAllocation at 0x7fb7adde7350>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22-SWKsLvqYK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "39eb62aa-4dc2-4e7c-cfaf-e3b499c00beb"
      },
      "source": [
        "run_align = parallel_align.get_function(\"compute_align\")\n",
        "run_align(seq_gpu, refs_gpu, score_matrix_gpu, num_refs_gpu, len_seq_gpu, len_refs_gpu, max_score_gpu, block = (10, 1, 1), grid = (10, 1, 1))\n",
        "score_out = np.empty((100, 100))\n",
        "cuda.memcpy_dtoh(score_out, score_matrix_gpu)\n",
        "print(score_out.shape)\n",
        "print(score_out.reshape(100, 100))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "error",
          "ename": "LogicError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLogicError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-186df82d4292>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_align\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparallel_align\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"compute_align\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrun_align\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_matrix_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_refs_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_seq_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_refs_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_score_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscore_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemcpy_dtoh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_matrix_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pycuda/compiler.py\u001b[0m in \u001b[0;36mget_function\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mSourceModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCudaModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLogicError\u001b[0m: cuModuleGetFunction failed: an illegal memory access was encountered"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIzo_xa6hqdU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4d003a5a-880b-4cbb-dc5c-4f5a478b9325"
      },
      "source": [
        "score_matrix.shape"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aazgufJSKJiX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score_matrix = np.zeros(len(seq) + 1, dtype=np.int32)\n",
        "print(score_matrix.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWeK2r0SMyOE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trace_matrix = np.zeros((REFERENCE_LENGTH+1, len(seq) + 1, 2), dtype=np.int32)\n",
        "print(trace_matrix.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4IuaetTKTsZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trace_matrix.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A15_xWpvrpiT",
        "colab_type": "text"
      },
      "source": [
        "Now create the calling code in Python (you can leave all the other functions as they were)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TM6sHA5rvTC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "offset = 0\n",
        "score = 0\n",
        "max_score = 0\n",
        "ref_idx = 0\n",
        "time_span = 0\n",
        "\n",
        "\n",
        "# Now run the same using our kernel\n",
        "t1 = time.time()\n",
        "\n",
        "refs = initialise_references()\n",
        "seq = initialise_sequence(refs)\n",
        "\n",
        "# Create arrays for the scoring matrix and traceback matrix\n",
        "score_matrix = np.zeros(len(seq) * NUMBER_REFERENCES, dtype=np.int32)\n",
        "trace_matrix = np.zeros((REFERENCE_LENGTH+1, len(seq) + 1, 2), dtype=np.int32)\n",
        "max_score_matrix = np.zeros(NUMBER_REFERENCES, dtype=np.int32)\n",
        "max_score = -len(seq)\n",
        "\n",
        "#convert strings to array\n",
        "seq_byte = bytearray(seq, 'utf8')\n",
        "seq_array = np.array(seq_byte)\n",
        "max_score_array = np.array(np.int(max_score))\n",
        "len_seq_array = np.array(np.int(SEQUENCE_LENGTH))\n",
        "len_refs_array = np.array(np.int(REFERENCE_LENGTH))\n",
        "num_refs_array = np.array(np.int(NUMBER_REFERENCES))\n",
        "max_idx_array = np.array(np.int(0))\n",
        "\n",
        "refs_array = []\n",
        "for i in range(len(refs)):\n",
        "  refs_array.append(bytearray(refs[i], 'utf8'))\n",
        "\n",
        "refs_array = np.array(refs_array)\n",
        "  \n",
        "#TODO - Insert data preparation code\n",
        "# Allocate GPU memory\n",
        "score_matrix_gpu = cuda.mem_alloc(score_matrix.nbytes)\n",
        "trace_matrix_gpu = cuda.mem_alloc(trace_matrix.nbytes)\n",
        "seq_gpu = cuda.mem_alloc(seq_array.nbytes)\n",
        "refs_gpu = cuda.mem_alloc(refs_array.nbytes)\n",
        "max_score_gpu = cuda.mem_alloc(max_score_array.nbytes)\n",
        "\n",
        "num_refs_gpu = cuda.mem_alloc(num_refs_array.nbytes)\n",
        "len_seq_gpu = cuda.mem_alloc(len_seq_array.nbytes)\n",
        "len_refs_gpu = cuda.mem_alloc(len_refs_array.nbytes)\n",
        "num_refs_gpu = cuda.mem_alloc(num_refs_array.nbytes)\n",
        "max_idx_gpu = cuda.mem_alloc(max_idx_array.nbytes)\n",
        "\n",
        "# set the gpu memory\n",
        "cuda.memcpy_htod(score_matrix_gpu, score_matrix)\n",
        "cuda.memcpy_htod(trace_matrix_gpu, trace_matrix)\n",
        "cuda.memcpy_htod(seq_gpu, seq_array)\n",
        "cuda.memcpy_htod(refs_gpu, refs_array)\n",
        "cuda.memcpy_htod(max_score_gpu, max_score_array)\n",
        "\n",
        "cuda.memcpy_htod(num_refs_gpu, num_refs_array)\n",
        "cuda.memcpy_htod(len_seq_gpu, len_seq_array)\n",
        "cuda.memcpy_htod(len_refs_gpu, len_refs_array)\n",
        "cuda.memcpy_htod(num_refs_gpu, num_refs_array)\n",
        "cuda.memcpy_htod(max_idx_gpu, max_idx_array)\n",
        "\n",
        "time_span = time.time() - t1\n",
        "print(\"Data initialisation took \" + str(time_span) + \" milliseconds.\")\n",
        "\n",
        "t1 = time.time()\n",
        "\n",
        "# Get the function handle\n",
        "\n",
        "# Create a lauch configuration with 10,0000 threads and 1 block\n",
        "#run_index = parallel_index.get_function(\"compute_index\")\n",
        "#run_index(seq_gpu, refs_gpu, score_matrix_gpu, block = (64, 1, 1), grid = (64, 1, 1))\n",
        "run_align = parallel_align.get_function(\"compute_align\")\n",
        "run_align(seq_gpu, refs_gpu, score_matrix_gpu, num_refs_gpu, len_seq_gpu, len_refs_gpu, max_score_gpu, block = (64, 1, 1), grid = (64, 1, 1))\n",
        "\n",
        "time_span = time.time() - t1\n",
        "\n",
        "# now get offset on the best reference match\n",
        "score, trace_matrix, offset_idx = align(seq, refs[max_idx], score_matrix, trace_matrix, compute_trace=True)\n",
        "\n",
        "offset = compute_offset(trace_matrix, len(seq), refs[max_idx], offset_idx)\n",
        "print(\"Optimal cost of \" + str(max_s) + \" found at offset \" + str(offset) + \" in reference \" + str(ref_idx))\n",
        "time_span = time.time() - t1\n",
        "print(\"CUDA version took \" + str(time_span) + \" seconds\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kK_LKMXZMzBy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = np.array([[1,2,3,4],[1,2,3,4],[1,2,3,4],[1,2,3,4]],dtype=np.uint32)\n",
        "b = np.array([[1,1,1,1],[2,2,2,2],[3,3,3,3],[4,4,4,4]],dtype=np.uint32)\n",
        "\n",
        "# Allocate GPU memory\n",
        "a_gpu = cuda.mem_alloc(a.nbytes)\n",
        "b_gpu = cuda.mem_alloc(b.nbytes)\n",
        "# set the gpu memory\n",
        "cuda.memcpy_htod(a_gpu, a)\n",
        "cuda.memcpy_htod(b_gpu, b)\n",
        "\n",
        "# Get the function handle\n",
        "func = mmult.get_function(\"multiply\")\n",
        "# Create a lauch configuration with 4 threads and 1 block\n",
        "func(a_gpu, b_gpu, block = (4,4,1))\n",
        "\n",
        "# Create array for output\n",
        "a_out = np.empty_like(a)\n",
        "# Copy the gpu memory to the host\n",
        "cuda.memcpy_dtoh(a_out, a_gpu)\n",
        "\n",
        "# Print data out\n",
        "print(a_out)\n",
        "\n",
        "# Free up the memory\n",
        "a_gpu.free()\n",
        "b_gpu.free()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}